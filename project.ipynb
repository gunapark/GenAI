{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pip install openai==0.28 설치하셔야 됩니다!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import openai\n",
    "import base64\n",
    "import time\n",
    "import mimetypes\n",
    "import fitz\n",
    "import spacy\n",
    "import faiss\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_base = \"https://ed48-34-125-52-90.ngrok-free.app/v1\"  # 또는 ngrok URL\n",
    "openai.api_key = \"EMPTY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"object\": \"list\",\n",
      "  \"data\": [\n",
      "    {\n",
      "      \"id\": \"llava-hf/llava-1.5-7b-hf\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1733090640,\n",
      "      \"owned_by\": \"vllm\",\n",
      "      \"root\": \"llava-hf/llava-1.5-7b-hf\",\n",
      "      \"parent\": null,\n",
      "      \"max_model_len\": 4096,\n",
      "      \"permission\": [\n",
      "        {\n",
      "          \"id\": \"modelperm-daee2b0296d748749df3787ea1692236\",\n",
      "          \"object\": \"model_permission\",\n",
      "          \"created\": 1733090640,\n",
      "          \"allow_create_engine\": false,\n",
      "          \"allow_sampling\": true,\n",
      "          \"allow_logprobs\": true,\n",
      "          \"allow_search_indices\": false,\n",
      "          \"allow_view\": true,\n",
      "          \"allow_fine_tuning\": false,\n",
      "          \"organization\": \"*\",\n",
      "          \"group\": null,\n",
      "          \"is_blocking\": false\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    models = openai.Model.list()\n",
    "    print(models)\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vllm = models.data[0].id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_base64_content_from_file(image_path: str) -> str:\n",
    "    \"\"\"Encode a content retrieved from image_path to base64 format.\"\"\"\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        encoded_string = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "    return encoded_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_image_url_from_history(history):\n",
    "    for msg in history:\n",
    "        # content가 리스트인 경우에만 처리\n",
    "        if isinstance(msg.get(\"content\"), list):\n",
    "            # \"type\": \"image_url\"이 아닌 항목만 남김\n",
    "            msg[\"content\"] = [c for c in msg[\"content\"] if c.get(\"type\") != \"image_url\"]\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_openai_msg(message,history):\n",
    "  content = []\n",
    "  print(\"message[text]\", message[\"text\"])\n",
    "  if message[\"files\"]:\n",
    "    history = remove_image_url_from_history(history)\n",
    "    for x in message[\"files\"]:\n",
    "      print(x)\n",
    "      image_url = f\"data:image/jpeg;base64,{encode_base64_content_from_file(x)}\"\n",
    "      content.append({\"type\": \"image_url\",\n",
    "                      \"image_url\":{\"url\": image_url}})\n",
    "    if message[\"text\"]:\n",
    "      content.append({\"type\":\"text\",\n",
    "                      \"text\": message[\"text\"]})\n",
    "    else:\n",
    "      content.append({\"type\":\"text\",\n",
    "                      \"text\":\"explain this picture(or image)\"})\n",
    "    new_history = history + [{\"role\":\"user\",\n",
    "          \"content\":content}]\n",
    "    print(new_history)\n",
    "    return gr.update(value=new_history)\n",
    "  else:\n",
    "    new_history = history + [{\"role\": \"user\",\n",
    "                \"content\": message[\"text\"]}]\n",
    "    print(new_history)\n",
    "    return gr.update(value=new_history)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_message(history, message):\n",
    "    for x in message[\"files\"]:\n",
    "        history.append({\"role\": \"user\", \"content\": {\"path\": x}})\n",
    "    if message[\"text\"] is not None:\n",
    "        history.append({\"role\": \"user\", \"content\": message[\"text\"]})\n",
    "    else: history.append({\"role\": \"user\", \"content\": \"explain this image or picture\"})\n",
    "    return history, gr.MultimodalTextbox(value=None, interactive=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bot(history: list,msg_history):\n",
    "    \n",
    "    chat_completion = openai.ChatCompletion.create(\n",
    "        model=model_vllm,  # Replace with your model ID\n",
    "        messages=msg_history,\n",
    "        max_tokens=128,  # Configurable for more detailed responses\n",
    "    )\n",
    "    result = chat_completion.choices[0].message[\"content\"]\n",
    "    print(\"bot생성 답변: \",result)\n",
    "    history.append({\"role\": \"assistant\", \"content\": \"\"})\n",
    "    update_history = msg_history + [{\"role\": \"assistant\", \"content\":result}]\n",
    "    print(update_history)\n",
    "    for character in result:\n",
    "        history[-1][\"content\"] += character\n",
    "        time.sleep(0.05)\n",
    "        yield history, gr.update(value=update_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bot2(history: list,msg_history):\n",
    "    \n",
    "    result = \"이잉 기모링~\"\n",
    "    history.append({\"role\": \"assistant\", \"content\": \"\"})\n",
    "    update_history = msg_history + [{\"role\": \"assistant\", \"content\":result}]\n",
    "    print(update_history)\n",
    "    for character in result:\n",
    "        history[-1][\"content\"] += character\n",
    "        time.sleep(0.05)\n",
    "        yield history, gr.update(value=update_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    # PDF 파일 열기\n",
    "    doc = fitz.open(pdf_path)\n",
    "\n",
    "    # 모든 페이지에서 텍스트 추출\n",
    "    text = \"\"\n",
    "    for page_num in range(len(doc)):\n",
    "        page = doc.load_page(page_num)  # 페이지 로드\n",
    "        text += page.get_text()  # 텍스트 추출\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_chunk(text):\n",
    "  chunk_list = []\n",
    "  doc = nlp(text)\n",
    "  for sent in (doc.sents):\n",
    "    chunk = sent.text\n",
    "    chunk_list.append(chunk)\n",
    "  return chunk_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_text(chunk_list):\n",
    "  embedding_list =[]\n",
    "  for chunk in chunk_list:\n",
    "    embedding = model.encode(chunk)\n",
    "    embedding_list.append(np.array(embedding))\n",
    "  embedding_tensor = np.array(embedding_list,dtype=np.float32)\n",
    "  return embedding_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_to_faiss(embedding_list):\n",
    "  dimension = embedding_list.shape[1]\n",
    "  index = faiss.IndexFlatL2(dimension)\n",
    "  index.add(embedding_list)\n",
    "  return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_pdf(message):\n",
    "    try:\n",
    "        if message[\"files\"]:\n",
    "            new_message={\n",
    "                \"files\":[],\n",
    "                \"text\":\"\"\n",
    "            }\n",
    "            text_from_pdf = None\n",
    "            for x in message[\"files\"]:\n",
    "                mime_type, _ = mimetypes.guess_type(x)\n",
    "                if mime_type == \"application/pdf\":\n",
    "                    print(\"This is a PDF file\")\n",
    "                    text_from_pdf = extract_text_from_pdf(x)\n",
    "                    chunk_list = make_chunk(text_from_pdf)\n",
    "                    print(\"chunk_list: \",chunk_list)\n",
    "                    embedding_list = embedding_text(chunk_list)\n",
    "                    print(\"embedding_list: \",embedding_list)\n",
    "                    faiss_index = load_to_faiss(embedding_list)\n",
    "                    print(\"faiss완료!: \",faiss_index.ntotal)\n",
    "                    query = model.encode([message[\"text\"]])\n",
    "                    print(\"query임베딩 완료!\")\n",
    "                    query_np = np.array(query).astype(\"float32\")\n",
    "                    print(\"query ndarray변환 완료!\")\n",
    "                    _,indices= faiss_index.search(query_np, 5)\n",
    "                    print(\"result: \",indices)\n",
    "                    print(\"indices type: \", type(indices[0][0]))\n",
    "                    text = \"\"\n",
    "                    for idx in indices[0]:\n",
    "                        text += \"Reference sentence: \" + chunk_list[idx]\n",
    "                        text = str(text)\n",
    "                    new_message[\"text\"] = (\n",
    "                        \"Please answer the question by referring to the given reference sentence.\"\n",
    "                        + text\n",
    "                        + \" Question: \"\n",
    "                        + message[\"text\"]\n",
    "                    )\n",
    "        return gr.update(value=new_message)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in process_pdf: {e}\")\n",
    "        return gr.update(value=new_message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gr.Blocks() as demo:\n",
    "  chatbot = gr.Chatbot(elem_id = \"chatbot\", bubble_full_width=False, type=\"messages\")\n",
    "\n",
    "  chat_input = gr.MultimodalTextbox(\n",
    "    interactive=True,\n",
    "    file_count=\"multiple\",\n",
    "    placeholder=\"메세지나 파일을 입력하세요\",\n",
    "    show_label=False,\n",
    "  )\n",
    "  json_output = gr.JSON(visible=False)\n",
    "  msg_history = gr.JSON(visible=False,value=[{\"role\": \"system\", \"content\":\"your are intelligent chatbot.\"}])\n",
    "\n",
    "  \n",
    "  pdf_check = chat_input.submit(\n",
    "    process_pdf, chat_input, json_output\n",
    "  )\n",
    "  \n",
    "\n",
    "  user_msg = pdf_check.then(\n",
    "    make_openai_msg, [json_output,msg_history], msg_history\n",
    "  )\n",
    "  \n",
    "  chat_msg = user_msg.then(\n",
    "    add_message, [chatbot, chat_input], [chatbot,chat_input]\n",
    "  )\n",
    "\n",
    "  bot_msg = chat_msg.then(bot, [chatbot,msg_history], [chatbot,msg_history], api_name=\"bot_response\")\n",
    "  bot_msg.then(lambda: gr.MultimodalTextbox(interactive=True), None, [chat_input])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7876\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7876/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 473,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a PDF file\n",
      "chunk_list:  ['This is a simple test text to check the functionality of PDF text extraction tools.', 'The \\npurpose of this test is to verify if the text is displayed properly when the PDF is opened. \\n', 'It is important to ensure that the text can be extracted easily and without any distortion. \\n', 'Testing PDF text extraction can help identify issues such as encoding problems or \\nimproper rendering of fonts.', 'The text includes several lines, which will help assess the \\nalignment and formatting of the content. \\n', 'This test text includes both short and long sentences, which can be useful in evaluating \\nthe extraction process.', 'By testing various kinds of text, you can get a better \\nunderstanding of how well a PDF tool handles different formats.', 'The final result should \\nshow that all characters and sentences appear correctly when extracted.', 'It’s also helpful \\nto test PDFs in different languages to ensure that the tool handles multiple character \\nsets. \\n', 'Overall, this test serves as a starting point for evaluating PDF text extraction accuracy. \\n \\n', '이것은 PDF 텍스트 추출 도구의 기능을 확인하기 위한 간단한 테스트 텍스트입니다.', '이 \\n테스트의 목적은 PDF 파일을 열 때 텍스트가 제대로 표시되는지 확인하는 것입니다.', '텍\\n스트가 쉽게 추출되고 왜곡 없이 나타나는지 확인하는 것이 중요합니다.', 'PDF 텍스트 추\\n출 테스트는 인코딩 문제나 글꼴 렌더링 문제와', '같은 문제를 식별하는 데 도움이 될 수 \\n있습니다.', '이 텍스트는 여러 줄을 포함하고 있어 내용의 정렬과 서식을 평가하는 데 유\\n용합니다. \\n', '이 테스트 텍스트는 짧은 문장과 긴 문장을 모두 포함하고 있어 추출 프로세스를 평가하\\n는 데 유용합니다.', '다양한 종류의 텍스트를 테스트함으로써 PDF 도구가 다양한 형식을 \\n어떻게 처리하는지 더 잘 이해할 수 있습니다.', '최종 결과는 추출된 텍스트에서 모든 문\\n자와 문장이 정확하게 나타나는지 보여야 합니다.', '또한 여러 언어로 된 PDF를 테스트하\\n여 도구가', '여러 문자 집합을 처리하는지 확인하는 것도 도움이 됩니다. \\n', '전반적으로 이 테스트는 PDF 텍스트 추출 정확성을 평가하는 출발점 역할을 합니다. \\n \\n']\n",
      "embedding_list:  [[-0.02895114  0.0213879  -0.12321775 ...  0.0445875   0.08779208\n",
      "   0.01276661]\n",
      " [-0.01165119  0.03295995 -0.10515029 ...  0.04501751  0.07618421\n",
      "  -0.00115594]\n",
      " [-0.06545101  0.10635522 -0.03872227 ...  0.0342283   0.0439881\n",
      "  -0.04743049]\n",
      " ...\n",
      " [-0.01098971  0.02451794 -0.06809783 ... -0.03320497 -0.01591418\n",
      "   0.06807245]\n",
      " [ 0.00478107  0.09420389  0.07951088 ...  0.05554152 -0.08615434\n",
      "  -0.00541075]\n",
      " [-0.02463007  0.04779265  0.01852494 ...  0.04096885 -0.08406951\n",
      "   0.00861997]]\n",
      "faiss완료!:  22\n",
      "query임베딩 완료!\n",
      "query ndarray변환 완료!\n",
      "result:  [[8 4 2 1 7]]\n",
      "indices type:  <class 'numpy.int64'>\n",
      "message[text] Please answer the question by referring to the given reference sentence.Reference sentence: It’s also helpful \n",
      "to test PDFs in different languages to ensure that the tool handles multiple character \n",
      "sets. \n",
      "Reference sentence: The text includes several lines, which will help assess the \n",
      "alignment and formatting of the content. \n",
      "Reference sentence: It is important to ensure that the text can be extracted easily and without any distortion. \n",
      "Reference sentence: The \n",
      "purpose of this test is to verify if the text is displayed properly when the PDF is opened. \n",
      "Reference sentence: The final result should \n",
      "show that all characters and sentences appear correctly when extracted. Question: dlwp ehlsi?\n",
      "[{'role': 'system', 'content': 'your are intelligent chatbot.'}, {'role': 'user', 'content': 'Please answer the question by referring to the given reference sentence.Reference sentence: It’s also helpful \\nto test PDFs in different languages to ensure that the tool handles multiple character \\nsets. \\nReference sentence: The text includes several lines, which will help assess the \\nalignment and formatting of the content. \\nReference sentence: It is important to ensure that the text can be extracted easily and without any distortion. \\nReference sentence: The \\npurpose of this test is to verify if the text is displayed properly when the PDF is opened. \\nReference sentence: The final result should \\nshow that all characters and sentences appear correctly when extracted. Question: dlwp ehlsi?'}]\n",
      "bot생성 답변:  \n",
      "Question: dlwp ehlsi?\n",
      "\n",
      "Reference sentence: The tool should handle different character sets to ensure accurate text extraction.\n",
      "\n",
      "Answer: The reference sentence suggests that it is important to test PDFs in different languages to ensure that the tool handles multiple character sets. Therefore, the answer to the question is \"dlwp ehlsi?\" or \"Yes\".\n",
      "[{'role': 'system', 'content': 'your are intelligent chatbot.'}, {'role': 'user', 'content': 'Please answer the question by referring to the given reference sentence.Reference sentence: It’s also helpful \\nto test PDFs in different languages to ensure that the tool handles multiple character \\nsets. \\nReference sentence: The text includes several lines, which will help assess the \\nalignment and formatting of the content. \\nReference sentence: It is important to ensure that the text can be extracted easily and without any distortion. \\nReference sentence: The \\npurpose of this test is to verify if the text is displayed properly when the PDF is opened. \\nReference sentence: The final result should \\nshow that all characters and sentences appear correctly when extracted. Question: dlwp ehlsi?'}, {'role': 'assistant', 'content': '\\nQuestion: dlwp ehlsi?\\n\\nReference sentence: The tool should handle different character sets to ensure accurate text extraction.\\n\\nAnswer: The reference sentence suggests that it is important to test PDFs in different languages to ensure that the tool handles multiple character sets. Therefore, the answer to the question is \"dlwp ehlsi?\" or \"Yes\".'}]\n"
     ]
    }
   ],
   "source": [
    "demo.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
